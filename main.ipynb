{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9681e85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys, datetime, time, random, fnmatch, math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import skimage.metrics\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as tvtransforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import datasets, transforms, RajaramanModel, pytorch_msssim\n",
    "\n",
    "flag_debug = False\n",
    "flag_load_previous_save = False\n",
    "\n",
    "# Input Directories\n",
    "#data_BSE = \"D:/data/JSRT/augmented/train/target/\"\n",
    "#data_normal = \"D:/data/JSRT/augmented/train/source/\"\n",
    "data_BSE = \"G:/DanielLam/JSRT/augmented/train/target\"\n",
    "data_normal = \"G:/DanielLam/JSRT/augmented/train/source\"\n",
    "\n",
    "# Save directories:\n",
    "output_save_directory = Path(\"./runs/Rajaraman_ResNet/v1\")\n",
    "output_save_directory.mkdir(parents=True, exist_ok=True)\n",
    "PATH_SAVE_NETWORK_INTERMEDIATE = os.path.join(output_save_directory, 'network_intermediate.tar' )\n",
    "PATH_SAVE_NETWORK = os.path.join(output_save_directory, 'network_final.pt')\n",
    "\n",
    "# Image Size:\n",
    "image_spatial_size = (256,256)\n",
    "_batch_size = 5\n",
    "test_length = 10\n",
    "\n",
    "# Optimisation\n",
    "lr_ini = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "\n",
    "# Training\n",
    "total_num_epochs = 150\n",
    "\n",
    "# Weight Initialisation\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        #nn.init.normal_(m.weight.data, 0., 0.02)\n",
    "        nn.init.kaiming_normal_(m.weight.data,0)\n",
    "        try:\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "        except:\n",
    "            pass\n",
    "    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "## Code for putting things on the GPU\n",
    "ngpu = 1 #torch.cuda.device_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "if (torch.cuda.is_available()):\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current date:\n",
    "current_date=datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Data Loader\n",
    "discriminator_keys_images = [\"source\", \"boneless\"]\n",
    "target_key = \"boneless\"\n",
    "ds = datasets.JSRT_CXR(data_normal, data_BSE,\n",
    "                         transform=tvtransforms.Compose([\n",
    "                             transforms.RescalingNormalisation(discriminator_keys_images,(0,1)),\n",
    "                             transforms.RandomIntensityComplement(discriminator_keys_images, probability=0.5),\n",
    "                             transforms.Rescale(image_spatial_size, discriminator_keys_images, None),\n",
    "                             transforms.ToTensor(discriminator_keys_images),\n",
    "                             ])\n",
    "                      )\n",
    "\n",
    "# SPLIT DATA INTO TRAINING/VALIDATION SET\n",
    "lengths=(len(ds)-test_length, test_length)\n",
    "print(lengths)\n",
    "ds_training, ds_val = torch.utils.data.random_split(ds, lengths)\n",
    "\n",
    "dl_training = DataLoader(ds_training, batch_size=_batch_size,\n",
    "                         shuffle=True, num_workers=0)\n",
    "\n",
    "dl_validation = DataLoader(ds_val, batch_size=1,\n",
    "                         shuffle=True, num_workers=0)\n",
    "fixed_val_sample = next(iter(dl_validation))\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(fixed_val_sample[\"source\"][0,0,:])\n",
    "ax[1].imshow(fixed_val_sample[\"boneless\"][0,0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementation of network and losses\n",
    "input_array_size = (_batch_size, 1, image_spatial_size[0], image_spatial_size[1])\n",
    "net = RajaramanModel.ResNet_BS(input_array_size)\n",
    "# Initialise weights\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Multi-GPU\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    print(\"Neural Net on GPU\")\n",
    "    net = nn.DataParallel(net, list(range(ngpu)))\n",
    "net = net.to(device)\n",
    "\n",
    "# Optimiser\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr_ini, betas=(beta1, beta2))\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                 factor=0.5, patience=10, \n",
    "                                                 threshold=0.0001, min_lr=0.00001, verbose=True)\n",
    "\n",
    "# Gusarev Loss\n",
    "def criterion_Rajaraman(testImage, referenceImage, alpha=0.84):\n",
    "    \"\"\"\n",
    "    Gusarev et al. 2017. Deep learning models for bone suppression in chest radiographs.  IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology.\n",
    "    \"\"\"\n",
    "    mae = nn.L1Loss() # L2 used for easier optimisation c.f. L1\n",
    "    mae_loss = mae(testImage, referenceImage)\n",
    "    msssim = pytorch_msssim.MSSSIM(window_size=11, size_average=True, channel=1, normalize='relu')\n",
    "    msssim_loss = 1 - msssim(testImage, referenceImage)\n",
    "    total_loss = (1-alpha)*mae_loss + alpha*msssim_loss\n",
    "    return total_loss, mae_loss, msssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs_list = []\n",
    "img_list = []\n",
    "loss_list = []\n",
    "reals_shown = []\n",
    "validation_loss_per_epoch_list = []\n",
    "training_loss_per_epoch_list = []\n",
    "ssim_training_list=[]\n",
    "ssim_val_list = []\n",
    "# For each epoch\n",
    "print(target_key)\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if flag_load_previous_save:\n",
    "    if os.path.isfile(PATH_SAVE_NETWORK_INTERMEDIATE):\n",
    "        print(\"=> loading checkpoint '{}'\".format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "        checkpoint = torch.load(PATH_SAVE_NETWORK_INTERMEDIATE)\n",
    "        start_epoch = checkpoint['epoch_next']\n",
    "        reals_shown_now = checkpoint['reals_shown']\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}, reals shown {})\".format(PATH_SAVE_NETWORK_INTERMEDIATE, \n",
    "                                                                            start_epoch, reals_shown_now))\n",
    "        print(scheduler)\n",
    "    else:\n",
    "        print(\"=> NO CHECKPOINT FOUND AT '{}'\" .format(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "        raise RuntimeError(\"No checkpoint found at specified path.\")\n",
    "else:\n",
    "    print(\"FLAG: NO CHECKPOINT LOADED.\")\n",
    "    reals_shown_now = 0\n",
    "    start_epoch=0\n",
    "\n",
    "# Loop variables\n",
    "flag_break = False # when debugging, this will automatically go to True\n",
    "iters = 0\n",
    "net.train()\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = True\n",
    "for epoch in range(start_epoch, total_num_epochs):\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for i, data in enumerate(dl_training):\n",
    "        # Training\n",
    "        net.zero_grad()\n",
    "        noisy_data = data[\"source\"].to(device)\n",
    "        cleaned_data = net(noisy_data)\n",
    "        loss, maeloss, msssim_loss = criterion_Rajaraman(cleaned_data, data[target_key].to(device))\n",
    "        loss.backward() # calculate gradients\n",
    "        optimizer.step() # optimiser step along gradients\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tTotal Loss: %.4f\\tMAELoss: %.4f\\tMSSSIM Loss: %.4f'\n",
    "                  % (epoch, total_num_epochs, i, len(dl_training),\n",
    "                     loss.item(), maeloss.item(), msssim_loss.item()))\n",
    "        # Record generator output\n",
    "        if reals_shown_now%(100*_batch_size)==0:\n",
    "            with torch.no_grad():\n",
    "                val_cleaned = net(fixed_val_sample[\"source\"].to(device)).detach().cpu()\n",
    "            print(\"Printing to img_list\")\n",
    "            img_list.append(vutils.make_grid(val_cleaned, padding=2, normalize=True))\n",
    "        iters +=1\n",
    "        reals_shown_now += _batch_size\n",
    "        reals_shown.append(reals_shown_now)\n",
    "        loss_list.append(loss.item()) # training loss\n",
    "        \n",
    "        if flag_debug and iters>=10:\n",
    "            flag_break = True\n",
    "            break\n",
    "    \n",
    "    # Training and Validation Loss and Accuracy\n",
    "    with torch.no_grad():\n",
    "        # Training\n",
    "        noisy_training_data = data[\"source\"][0:1,:].to(device)\n",
    "        true_training_data = data[target_key][0:1,:]\n",
    "        cleaned_training_data = net(noisy_training_data)\n",
    "        loss, maeloss, msssim_loss = criterion_Rajaraman(cleaned_training_data, true_training_data.to(device))\n",
    "        training_loss_per_epoch_list.append(loss.item())\n",
    "        \n",
    "        clean_training_numpy = cleaned_training_data.cpu().detach().numpy()[0,:]\n",
    "        true_training_numpy = true_training_data.numpy()[0,:]\n",
    "        clean_training_numpy = np.moveaxis(clean_training_numpy, 0, -1)\n",
    "        true_training_numpy = np.moveaxis(true_training_numpy, 0, -1)\n",
    "        ssim_training = skimage.metrics.structural_similarity(clean_training_numpy, true_training_numpy, multichannel=True)\n",
    "        ssim_training_list.append(ssim_training)\n",
    "        \n",
    "        # Validation\n",
    "        sample = next(iter(dl_validation))\n",
    "        noisy_val_data = sample[\"source\"][0:1,:].to(device)\n",
    "        true_val_data = sample[target_key][0:1,:]\n",
    "        cleaned_val_data = net(noisy_val_data)\n",
    "        val_loss, maeloss, msssim_loss = criterion_Rajaraman(cleaned_val_data, true_val_data.to(device))\n",
    "        validation_loss_per_epoch_list.append(val_loss.item())\n",
    "        \n",
    "        clean_val_numpy = cleaned_val_data.cpu().detach().numpy()[0,:]\n",
    "        true_val_numpy = true_val_data.numpy()[0,:]\n",
    "        clean_val_numpy = np.moveaxis(clean_val_numpy, 0, -1)\n",
    "        true_val_numpy = np.moveaxis(true_val_numpy, 0, -1)\n",
    "        ssim_val = skimage.metrics.structural_similarity(clean_val_numpy, true_val_numpy, multichannel=True)\n",
    "        ssim_val_list.append(ssim_val)\n",
    "    \n",
    "    epochs_list.append(epoch)\n",
    "    # LR Scheduler after epoch\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save the network in indications\n",
    "    if epoch % 5 == 0:\n",
    "        if not flag_debug:\n",
    "            #torch.save(net.state_dict(), PATH_SAVE_NETWORK_INTERMEDIATE)\n",
    "            torch.save({\n",
    "            'epochs_completed': epoch+1,\n",
    "            'epoch_next': epoch+1,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'reals_shown': reals_shown_now\n",
    "            }, PATH_SAVE_NETWORK_INTERMEDIATE)\n",
    "            print(\"Saved Intermediate: \"+ str(PATH_SAVE_NETWORK_INTERMEDIATE))\n",
    "    if flag_break:\n",
    "        break\n",
    "\n",
    "if not flag_debug:\n",
    "    torch.save(net.state_dict(), PATH_SAVE_NETWORK)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "current_date=datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"SSIM\")\n",
    "plt.plot(epochs_list, ssim_training_list, label='training')\n",
    "plt.plot(epochs_list, ssim_val_list, label='validation')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Loss for training\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Loss During Training\")\n",
    "plt.plot(reals_shown, loss_list)\n",
    "plt.xlabel(\"reals_shown\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, current_date + \"training_loss\"+\".png\"))\n",
    "\n",
    "# Final Model:\n",
    "with torch.no_grad():\n",
    "    input_image = fixed_val_sample['source']\n",
    "    input_images = vutils.make_grid(input_image[0:1,:,:,:], padding=2, normalize=True)\n",
    "    target_images = vutils.make_grid(fixed_val_sample['boneless'][0:1,:,:,:], padding=2, normalize=True)\n",
    "    net = net.cpu()\n",
    "    output_image = net(input_image[0:1,:,:,:]).detach().cpu()\n",
    "    output_images = vutils.make_grid(output_image, padding=2, normalize=True)\n",
    "print(str(torch.max(output_images)) + \",\" + str(torch.min(output_images)))\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,15))\n",
    "ax[0].imshow(np.transpose(input_images, (1,2,0)), vmin=0, vmax=1)\n",
    "ax[0].set_title(\"Source\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(np.transpose(output_images, (1,2,0)), vmin=0, vmax=1)\n",
    "ax[1].set_title(\"Suppressed\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(np.transpose(target_images, (1,2,0)), vmin=0, vmax=1)\n",
    "ax[2].set_title(\"Ideal Bone-suppressed\")\n",
    "ax[2].axis(\"off\")\n",
    "plt.show\n",
    "if not flag_debug:\n",
    "    plt.savefig(os.path.join(output_save_directory, current_date + \"_validation_ComparisonImages\"+\".png\"))\n",
    "\n",
    "# ANIMATED VALIDATION IMAGE\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.axis(\"off\")\n",
    "ims = []\n",
    "training_ims_shown = []\n",
    "for i, im in enumerate(img_list):\n",
    "    if i % 50 == 0:  # controls how many images are printed into the animation\n",
    "        training_ims_shown = i*(100*_batch_size)\n",
    "        frame = ax.imshow(np.transpose(im,(1,2,0)))\n",
    "        t = ax.annotate(\"Reals shown: {}\".format(training_ims_shown), (0.5,1.02), xycoords=\"axes fraction\")\n",
    "        ims.append([frame, t])\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=200, repeat_delay=1000, blit=True)\n",
    "if not flag_debug:\n",
    "    ani.save(os.path.join(output_save_directory, current_date+\"_animation.mp4\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2629b16-eb3e-4054-8b5c-b156e59596b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_numpy = cleaned_training_data.cpu().detach().numpy()[0,:]\n",
    "print(np.moveaxis(clean_training_numpy,0,-1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
